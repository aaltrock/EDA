clear();
addpath(genpath('.'));

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CONFIGURATIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Exprimental code for Neural Networks                  %
% The code is developed for Neural Computing tutorial   %
% MSc Data Science, CITY UNIVERSITY LONDON              %
% Authors: Son Tran, Artur Garcez                       %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% conf.hidNum = [20, 30]; % number of nodes in each hidden layer
% conf.activationFnc =  % tansig, logsig, purelin
% conf.eNum   = 10;% epoch number
% conf.bNum   = 10; % batch number
% conf.sNum   = round(trn_size/10); % sample size per batch
% conf.params = [0.5 0.1 0.1 0.0001];
% 
% conf.E_STOP = 10;

% Configuration - percentage of population for validation and test
% Note: training size is the remainder of validation and test
val_pct = 0.15;
tst_pct = 0.15;

% conf.hidNum = [20, 30]; % number of nodes in each hidden layer
% conf.activationFnc = ('tansig','logsig','tansig'); % tansig, logsig, purelin
% conf.eNum   = 10;% set number of epochs
% conf.bNum   = 0; % set later in each dataset
% conf.sNum   = 0; % set later in each dataset
% conf.params = [0.5 0.1 0.1 0.0001];

% Configuration - feed forward hidden layers configuration
ff_hidden_layers = [20]; % Vector of neuro numbers per hidden layer
activationFnc = "tansig"; % Activation functions: 'tansig','logsig','tansig'
ff_trn_func = "trainbr"; % Training function
batch_nbr = 10; % Batch number
flag_batching = true;
max_epoch = 20; % Max no. of epoch
E_STOP = 10; % 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DATA IMPORT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
disp("DATA IMPORT...");
% Read in the pre-processed file generated by Python code
src = readtable('src_df.xlsx');

% Extract the independent variables
src_x = src(:, 2:end);

% Extract the dependent variable
% (specifically 'Edible' variable only as the target)
src_y = src(:, 1);

% Convert from tables to matrix
src_x = table2array(src_x);
src_y = table2array(src_y);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% REPLACE NaN WITH VARIABLE MEANS IN INDEPENDENT VARRIABLES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

disp("REPLACING NaN WITH VARIABLE MEAN...");

% For every column in the independent variable set
for j = 1:size(src_x,2)
    % Calculate variable mean (excluding NaN)
    x_mean = mean(src_x(:,j), "omitnan");
    fprintf('Column: %d Mean: %d.2', j, x_mean);
    % For every row in the column
    for i = 1:size(src_x,1)
        if isnan(src_x(i, j))
            % Replace NaN with mean
            src_x(i,j) = x_mean;
        end
    end
end


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SIZES FOR TRAINING, VALIDATION & TESTING
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
disp("DETERMINE TRAIN, VALIDATION, TEST SET SIZES...");
% Determine size of the training, validation and test set
pop_size = size(src, 1);

disp("Population size:");
disp(pop_size);

val_size = round(val_pct * pop_size);
disp("Validation size:");
disp(val_size);

tst_size = round(tst_pct * pop_size);
disp("Test size:");
disp(tst_size);

% Training set size is the remainder of population after validation and
% test
trn_size = pop_size - val_size - tst_size;
disp("Training size:");
disp(trn_size);

% Validate the total size corresponds to original population size
disp("Training + Validation + Test size:");
disp(trn_size + val_size + tst_size);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% RANDOM SELECTIONS FOR TESTING, VALIDATION & TRAINING SETS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
disp("SELECTION FOR TRAIN, VALIDATION, TEST SETS...");
% Randomly select from index for test per calculated size
tst_idx = randsample(pop_size,tst_size);

% Remove samples selected for testing
trn_val_idx = [];
for i = 1:pop_size
    % If sample not selected in test, add to training and validation set
    if ~ismember(i, tst_idx)
        trn_val_idx = [trn_val_idx; i];
    end
end

% Randomly select from remainder for validation per calculated size
trn_val_rand_idx = randsample(size(trn_val_idx, 1), tst_size);

% Compile validation samples set
val_idx = [];
for i = trn_val_rand_idx
    % Add validation set samples selected randomly by index
    val_idx = [val_idx; trn_val_idx(i)];
end

% Compile training samples set by remainder after test and validation
% selections
trn_idx = [];
for i = 1:size(trn_val_idx,1)
    % If sample not selected in validation, add to training
    if ~ismember(trn_val_idx(i), val_idx)
        trn_idx = [trn_idx; trn_val_idx(i)];
    end
end

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% COMPILE TRAINING, VALIDATION & TEST SETS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
disp("COMPILE TRAIN, VALIDATION, TEST SETS...");
% Compile training set
trn_x = create_nn_sample_set(trn_idx, src_x);
trn_y = create_nn_sample_set(trn_idx, src_y);
trn_xy = [trn_x trn_y];

% Compile validation set
val_x = create_nn_sample_set(val_idx, src_x);
val_y = create_nn_sample_set(val_idx, src_y);

% Compile test set
tst_x = create_nn_sample_set(tst_idx, src_x);
tst_y = create_nn_sample_set(tst_idx, src_y);



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TRAINING FEEDFORWARD
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
disp("TRAINING FFN...");
% Construct a feed forward neural network
ff_net = fitnet(ff_hidden_layers, ff_trn_func);
view(ff_net);

% Configure neural network
ff_net.trainParam.epochs=max_epoch; % Epoch

% If batch is used
if flag_batching
    disp("Batching selected.");
    batch_size = round(size(trn_x, 1) / batch_nbr, 0); % sample size per batch
    fprintf("Batch size: %d Batch no.: batch_nbr %d", batch_size, batch_nbr);
    ff_net.trainParam
else
    disp("Batching not selected.");
end

% Train network with re-sampled data
ff_net = train(ff_net, transpose(trn_x), transpose(trn_y));
disp(ff_net.trainParam);


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% EVALUATE WITH VALIDATION SET
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
disp("VALIDATE FFN...");
% Predict with validation set
val_p = transpose(ff_net(transpose(val_x)));

% Compare predicted with actuals
[val_p_confusion_tbl, val_p_tbl, val_performance_tbl] = calc_actual_v_pred(val_p, val_y);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% EVALUATE WITH TEST SET
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
disp("TEST FFN...");
% Predict with test set
tst_p = transpose(ff_net(transpose(tst_x)));

% Compare predicted with actuals
[tst_p_confusion_tbl, tst_p_tbl, tst_performance_tbl] = calc_actual_v_pred(tst_p, tst_y);





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% RESAMPLE TO BALANCE MINORITY CLASSES IN TARGET VARIABLE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% % Apply SMOTE to balance minor classes
% [trn_x_SMOTE, trn_y_SMOTE] = SMOTE(trn_x, trn_y);
% 
% % In training set, count the frequency per class in the target variable
% [grp_cnt, grp_class] = groupcounts(trn_y);
% trn_y_cnt = [grp_class, grp_cnt];
% grp_cnt_pct = trn_y_cnt(:,2) ./ sum(trn_y_cnt(:,2)) .* 100; %Frequency per closed code
% grp_cnt_rank_idc = floor(tiedrank(trn_y_cnt(:,2))); %Rank incdices of count ascending
% trn_y_cnt = [trn_y_cnt, grp_cnt_pct, grp_cnt_rank_idc];
% 
% % In training set, count the frequency per class in the target variable
% [grp_SMOTE_cnt, grp_SMOTE_class] = groupcounts(trn_y_SMOTE);
% trn_y_SMOTE_cnt = [grp_SMOTE_class, grp_SMOTE_cnt];
% grp_cnt_SMOTE_pct = trn_y_SMOTE_cnt(:,2) ./ sum(trn_y_SMOTE_cnt(:,2)) .* 100; %Frequency per closed code
% grp_cnt_rank_SMOTE_idc = floor(tiedrank(trn_y_SMOTE_cnt(:,2))); %Rank incdices of count ascending
% trn_y_SMOTE_cnt = [trn_y_SMOTE_cnt, grp_cnt_SMOTE_pct, grp_cnt_rank_SMOTE_idc];
% 

% % In training set, count the frequency per class in the target variable
% [grp_cnt, grp_class] = groupcounts(trn_y);
% trn_y_cnt = [grp_class, grp_cnt];
% grp_cnt_pct = trn_y_cnt(:,2) ./ sum(trn_y_cnt(:,2)) .* 100; %Frequency per closed code
% grp_cnt_rank_idc = floor(tiedrank(trn_y_cnt(:,2))); %Rank incdices of count ascending
% trn_y_cnt = [trn_y_cnt, grp_cnt_pct, grp_cnt_rank_idc];
% 
% disp('No. of classes:');
% disp(size(trn_y_cnt,1));
% 
% % Calculate mean class size
% class_mean = floor(mean(trn_y_cnt(:,2)));
% 
% % Re-sample by adjusting the class size in training set to mean class size
% trn_xy_resampled = [];
% for i = 1:size(trn_y_cnt,1)
%     disp(i);
%     class_val = trn_y_cnt(i,1);
%     new_trn_xy = adjust_samples(class_val, trn_xy, class_mean);
%     trn_xy_resampled = [trn_xy_resampled; new_trn_xy];
% end
% 
% % Split training set to dependent and independent variables
% trn_x_resampled = trn_xy_resampled(:,1:size(trn_xy_resampled,2)-1);
% trn_y_resampled = trn_xy_resampled(:,size(trn_xy_resampled,2));
% 
% 
% % In training set, re-count the frequency per class in re-sampled training set
% [grp_cnt_resampled, grp_class_resampled] = groupcounts(trn_y_resampled);
% trn_y_cnt_resampled = [grp_class_resampled, grp_cnt_resampled];
% grp_cnt_resampled_pct = trn_y_cnt_resampled(:,2) ./ sum(trn_y_cnt_resampled(:,2)) .* 100; %Frequency per closed code
% grp_cnt_rank_resampled_idc = floor(tiedrank(trn_y_cnt_resampled(:,2))); %Rank incdices of count ascending
% trn_y_cnt_resampled = [trn_y_cnt_resampled, grp_cnt_resampled_pct, grp_cnt_rank_resampled_idc];



% % Evaluate with validation set
% val_perf = perform(ff_net, val_x, val_y);
% disp(ff_net.performFcn);
% fprintf("MSE: %d\n", val_perf);


